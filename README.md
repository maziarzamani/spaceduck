<p align="center">
  <img src="docs/assets/spaceduck-logo.png" alt="Spaceduck" width="280">
</p>

<p align="center">
  <strong>A tiny space duck. A big mission. Your new co-pilot has feathers.</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/runtime-Bun_1.3+-f9f1e1?style=for-the-badge&logo=bun&logoColor=14151a" alt="Bun">
  <img src="https://img.shields.io/badge/language-TypeScript-3178c6?style=for-the-badge&logo=typescript&logoColor=white" alt="TypeScript">
  <img src="https://img.shields.io/badge/database-SQLite-003B57?style=for-the-badge&logo=sqlite&logoColor=white" alt="SQLite">
  <img src="https://img.shields.io/github/actions/workflow/status/maziarzamani/spaceduck/ci.yml?style=for-the-badge&logo=githubactions&logoColor=white&label=CI" alt="CI">
</p>

> [!WARNING]
> **This project is experimental and under active development.**
> The API, configuration format, database schema, and memory architecture may change without notice between versions.
> Breaking changes are expected before v1.0 â€” including a planned replacement of the current `.env` configuration
> with a structured config file. Use in production at your own risk.

---

**Spaceduck** is a local-first AI assistant with persistent memory.

It remembers what you've said across conversations, acts on your behalf with real tools, and runs entirely on your machine. No agent frameworks, no orchestration wrappers â€” every layer (context management, vector memory, fact extraction, provider abstraction, streaming protocol) is "handwritten" TypeScript on Bun.

## Features

### Persistent Memory
- **Hybrid recall** (vector cosine + FTS5 BM25) â€” finds what you said even when you don't use the same words
- **Eager extraction** â€” facts are persisted after every response via `afterTurn()`, not only at compaction
- **SHA-256 deduplication** â€” exact-duplicate facts are caught before they hit storage
- **Memory firewall** (`guardFact`) â€” rejects questions, noisy content, and hallucinated facts
- **Recency decay + expiry** â€” older facts fade gracefully; stale facts are filtered at the SQL level

### Multi-Channel
- **Web UI** â€” React chat with streaming deltas, conversations sidebar, Tailwind CSS
- **WhatsApp** â€” Baileys (WhatsApp Web protocol), QR pairing, typing indicators
- **Desktop app** â€” Tauri v2 shell with Bun gateway sidecar â€” macOS, Linux, Windows
- Discord, Telegram, and CLI planned

### Agentic Tools
- **Web search** â€” Brave, Perplexity Sonar, or SearXNG â€” structured results plus AI-synthesized answers
- **Browser automation** â€” Playwright headless with accessibility-snapshot element refs
- **Web fetch** â€” HTTP fetch with HTML-to-text conversion for any public page
- **Document scanning** â€” Upload PDFs via the web UI (drag-and-drop or file picker), auto-convert to markdown with [Marker](https://github.com/VikParuchuri/marker) (optional, user-installed)
- Multi-round tool execution â€” the agent loop chains tool â†’ result â†’ LLM cycles automatically

### Provider Freedom
- **Gemini** â€” chat streaming + embeddings via Google AI
- **AWS Bedrock** â€” native Converse API, Titan Text Embeddings V2, Bearer token auth
- **OpenRouter** â€” access to hundreds of models through a single key
- **LM Studio** â€” any local model via OpenAI-compatible API
- Swap chat or embedding provider with a single env var; bring your own by implementing the `Provider` interface

### Built for Developers
- Zero framework dependencies â€” no LangChain, no LlamaIndex, no hidden abstractions
- `Result<T, E>` monads â€” errors are values, not exceptions
- Typed `EventBus` â€” fire-and-forget + async emit powers the fact extraction pipeline
- Token-budgeted context builder with automatic compaction
- Streaming protocol delivers tokens over WebSocket to the UI in real time

<p align="center">
  <img src="docs/assets/desktop-app-screen.png" alt="Spaceduck Desktop App" width="720">
</p>

## Status

> **Tested** column: `E2E` = verified against live APIs/services, `Unit` = tested with mocks, `â€”` = no automated tests yet.

### Core

| Component | | Details | Tested |
|-----------|---|---------|--------|
| Types & contracts | âœ… | `Message`, `Attachment`, `Provider`, `EmbeddingProvider`, `ConversationStore`, `LongTermMemory`, `Result<T>` monad | Unit |
| Context builder | âœ… | Token budgeting, system prompt injection, LTM fact recall, auto-compaction, afterTurn eager flush, attachment hints for tool invocation | Unit |
| Agent loop | âœ… | Multi-round tool execution with automatic tool â†’ result â†’ LLM cycles | Unit |
| Event bus | âœ… | Typed fire-and-forget + async emit, powers the fact extraction pipeline | Unit |
| Configuration system | ðŸ”œ | Structured config file replacing `.env` â€” type-safe, nestable, multi-environment | â€” |
| Plugin lifecycle | ðŸ”œ | Standardized init/shutdown hooks for providers, channels, and tools | â€” |
| Streaming protocol v2 | ðŸ”œ | Structured envelopes for tool progress, memory events, and error recovery | â€” |

### Memory

| Component | | Details | Tested |
|-----------|---|---------|--------|
| Conversation store | âœ… | Full message history in SQLite with WAL mode | Unit |
| Long-term facts | âœ… | Durable personal facts with FTS5 full-text search, identity slot model (`name`/`age`/`location`/`preference`) | Unit |
| Vector embeddings | âœ… | sqlite-vec cosine similarity, configurable dimensions, `minScore` filtering, FTS5 fallback, purpose-aware embeddings (`index`/`retrieval`) | Unit |
| Fact extraction | âœ… | Regex-first + LLM-second pipeline, pre-context extraction for same-turn updates, V2 Danish grammar support, symmetric negation detection | Unit |
| Deduplication | âœ… | SHA-256 content hashing with Unicode normalization for exact duplicates | Unit |
| Hybrid recall | âœ… | RRF combining vector cosine + FTS5 BM25, recency decay, SQL expiry pushdown | Unit |
| Fact conflict resolution | âœ… | Transactional `upsertSlotFact` with SQL write guards: `pre_regex` beats `post_llm` per message, time-ordering prevents stale overwrites | Unit |
| Backfill script | ðŸ”œ | Resumable migration to embed existing unembedded facts | â€” |
| Memory inspector | ðŸ”œ | Web UI panel to browse, edit, and delete stored facts | â€” |
| Per-user isolation | ðŸ”œ | Scope facts by user identity across channels | â€” |

**Language support for fact extraction:**
Regex extraction (same-turn, deterministic) currently covers English and Danish. Adding a language requires a small regex "booster pack" for identity patterns. LLM extraction (post-response, best-effort) works in any language the configured chat model understands. Embedding recall (cross-conversation) depends on the embedding model â€” most modern models support 100+ languages.

### Providers

| Component | | Details | Tested |
|-----------|---|---------|--------|
| Provider interface | âœ… | Pluggable `Provider` and `EmbeddingProvider` contracts â€” bring any model | Unit |
| Gemini | âœ… | Chat streaming + embeddings via Google AI | E2E |
| LM Studio | âœ… | Chat streaming + embeddings via OpenAI-compatible API (any local model) | â€” |
| OpenRouter | âœ… | Multi-model chat streaming (access to hundreds of models) | â€” |
| AWS Bedrock | âœ… | Native Converse API (required for Nova), Titan Text Embeddings V2, Bearer token auth | E2E |
| Embedding factory | âœ… | Provider-agnostic creation from env config, fail-fast dimension validation | Unit |
| Ollama | ðŸ”œ | Local models via Ollama API | â€” |
| Anthropic (direct) | ðŸ”œ | Claude via Anthropic API (non-Bedrock) | â€” |
| Provider fallback chain | ðŸ”œ | Auto-retry with secondary provider on failure or timeout | â€” |

### Channels & Interface

| Component | | Details | Tested |
|-----------|---|---------|--------|
| Web UI | âœ… | React chat with streaming, conversations sidebar, file upload (drag-drop + paperclip), attachment chips, Tailwind CSS | â€” |
| Gateway | âœ… | Bun HTTP + WebSocket server, session management, run locking, `POST /api/upload` with magic-byte validation | E2E |
| File uploads | âœ… | Multipart upload, PDF magic-byte validation, opaque attachment IDs, server-side `AttachmentStore` with TTL sweeper | Unit |
| WhatsApp | âœ… | Baileys (WhatsApp Web protocol), QR pairing, typing indicators | â€” |
| Discord | ðŸ”œ | Discord bot channel | â€” |
| Telegram | ðŸ”œ | Telegram bot channel | â€” |
| Desktop app | âœ… | Tauri v2 shell + Bun gateway sidecar â€” macOS, Linux, Windows | â€” |
| CLI | ðŸ”œ | Terminal-based chat interface | â€” |
| Multi-user auth | ðŸ”œ | Token-based auth for Web UI, per-user sessions | â€” |

### Tools

| Component | | Details | Tested |
|-----------|---|---------|--------|
| Browser | âœ… | Playwright headless with accessibility snapshot refs | E2E |
| Web fetch | âœ… | HTTP fetch + HTML-to-text conversion | E2E |
| Web search | âœ… | Brave / Perplexity Sonar / SearXNG â€” structured search + AI-synthesized answers | Unit |
| Document scan | âœ… | PDF-to-markdown via [Marker](https://github.com/VikParuchuri/marker) (optional, user-installed). Auto-registered when `marker_single` is on PATH. Configurable timeout, page range, OCR | Unit |
| Scheduler | ðŸ”œ | Periodic web monitoring with natural language conditions | â€” |
| File system | ðŸ”œ | Read/write local files with sandboxed access | â€” |
| Code interpreter | ðŸ”œ | Execute code snippets in a sandboxed runtime | â€” |

## Architecture

```mermaid
graph TD
    UI["Web UI (React)<br/>WebSocket + streaming deltas<br/>file upload (drag-drop / picker)"]
    WA["WhatsApp (Baileys)<br/>QR pairing Â· typing indicators"]
    GW["Gateway (Bun)<br/>HTTP server Â· WS handler Â· sessions<br/>POST /api/upload"]
    AS["Attachment Store<br/>opaque IDs Â· file sweeper"]
    AL["Agent Loop<br/>+ tool cycles"]
    CB["Context Builder<br/>+ budget Â· compact<br/>+ attachment hints"]
    MEM["Memory (SQLite)<br/>conversations Â· facts<br/>vector embeddings (vec0)<br/>FTS5 search Â· SHA-256 dedup"]
    CP["Chat Provider<br/>(pluggable)<br/>streaming chunks"]
    EP["Embedding Provider<br/>(pluggable)<br/>configurable dimensions"]
    TOOLS["Tools<br/>browser Â· fetch Â· search<br/>marker_scan Â· (extensible)"]

    UI --> GW
    WA --> GW
    GW --> AS
    GW --> AL
    GW --> CB
    GW --> MEM
    AL --> CP
    AL --> TOOLS
    TOOLS -->|"resolve attachmentId"| AS
    MEM --> EP
```

## Memory System

Spaceduck has a three-tier memory architecture:

1. **Short-term** â€” Full conversation message history in SQLite, with token-budgeted context windows and automatic compaction.

2. **Long-term (facts)** â€” Durable personal facts extracted from conversations. Extracted eagerly after every turn via `afterTurn()` (not only at compaction), and stored with SHA-256 content hashes for exact deduplication. A memory firewall (`guardFact`) validates facts before storage, rejecting questions and noisy content.

3. **Vector embeddings** â€” Every fact is embedded via a configurable `EmbeddingProvider` and stored in a sqlite-vec virtual table. Recall uses hybrid scoring: Reciprocal Rank Fusion (RRF) combining vector cosine similarity and FTS5 BM25, with exponential recency decay and SQL-level expiry filtering.

```mermaid
flowchart TD
    A["User message â†’ Agent Loop â†’ Assistant response"]
    B["afterTurn() eager flush<br/>(background, every response)"]
    C["LLM extracts personal facts"]
    D["guardFact() â†’ remember()<br/>SHA-256 dedup â†’ embed()<br/>â†’ store in facts + vec_facts"]
    E["recall(topic, topK, strategy)"]
    F["Hybrid: RRF(vector + FTS5)<br/>+ recency decay + expiry filter"]
    G["FTS5-only fallback<br/>(when embeddings disabled)"]

    A --> B --> C --> D
    D -->|"On next query"| E
    E --> F
    E --> G
```

## Project Structure

```
spaceduck/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                   # Web deployment entry point (served by gateway)
â”‚   â”‚   â”œâ”€â”€ index.html         # HTML entry + font preloads
â”‚   â”‚   â””â”€â”€ src/client.tsx     # React mount (imports @spaceduck/ui)
â”‚   â””â”€â”€ desktop/               # Tauri v2 desktop app (macOS, Linux, Windows)
â”‚       â”œâ”€â”€ src-tauri/         # Rust shell, sidecar config, capabilities
â”‚       â””â”€â”€ tooling/           # Build scripts (sidecar + frontend)
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                  # Zero-dep contracts + logic
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ types/         # Message, Attachment, Provider, EmbeddingProvider, Memory, Errors
â”‚   â”‚       â”œâ”€â”€ agent.ts       # AgentLoop orchestrator with multi-round tool calling
â”‚   â”‚       â”œâ”€â”€ context-builder.ts  # Token budget, compaction, afterTurn eager flush, attachment hints
â”‚   â”‚       â”œâ”€â”€ fact-extractor.ts   # Regex-first + LLM fact extraction with slot conflict resolution
â”‚   â”‚       â”œâ”€â”€ events.ts      # Typed EventBus (fire-and-forget + async)
â”‚   â”‚       â””â”€â”€ config.ts
â”‚   â”œâ”€â”€ ui/                    # Shared React components, hooks, and styles
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ app.tsx            # Root App component
â”‚   â”‚       â”œâ”€â”€ components/        # Sidebar, MessageList, ChatInput (file attach + drag-drop), StatusBar
â”‚   â”‚       â”œâ”€â”€ hooks/             # useSpaceduckWs (auto-detects Tauri vs web, supports attachments)
â”‚   â”‚       â””â”€â”€ styles.css         # Tailwind CSS
â”‚   â”œâ”€â”€ providers/             # Pluggable â€” add your own by implementing Provider interface
â”‚   â”‚   â”œâ”€â”€ gemini/            # Google AI (chat + embeddings)
â”‚   â”‚   â”œâ”€â”€ bedrock/           # Amazon Bedrock (native Converse API + Titan V2 embeddings)
â”‚   â”‚   â”œâ”€â”€ lmstudio/          # Local models via OpenAI-compatible API
â”‚   â”‚   â””â”€â”€ openrouter/        # Multi-model gateway
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ sqlite/            # SQLite + FTS5 + sqlite-vec vector storage
â”‚   â”‚       â””â”€â”€ src/
â”‚   â”‚           â”œâ”€â”€ schema.ts      # Migrations + ensureCustomSQLite()
â”‚   â”‚           â”œâ”€â”€ long-term.ts   # Hybrid recall (RRF) + vector + FTS + dedup
â”‚   â”‚           â””â”€â”€ migrations/    # 001â€“007 SQL migrations
â”‚   â”œâ”€â”€ channels/
â”‚   â”‚   â””â”€â”€ whatsapp/          # WhatsApp via Baileys (QR pairing)
â”‚   â”œâ”€â”€ gateway/               # Composition root â€” wires everything
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ gateway.ts         # HTTP/WS server + upload endpoint + dependency injection
â”‚   â”‚       â”œâ”€â”€ attachment-store.ts   # Server-side Map<attachmentId, localPath> with TTL sweeper
â”‚   â”‚       â”œâ”€â”€ tool-registrations.ts # Registers all built-in tools (including conditional marker_scan)
â”‚   â”‚       â””â”€â”€ embedding-factory.ts  # Provider-agnostic embedding creation
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ browser/           # Playwright headless browser
â”‚       â”œâ”€â”€ web-fetch/         # HTTP fetch + HTML-to-text
â”‚       â”œâ”€â”€ web-search/        # Brave / Perplexity Sonar / SearXNG search + answers
â”‚       â””â”€â”€ marker/            # PDF-to-markdown via Marker (optional, user-installed)
â””â”€â”€ package.json               # Bun workspace root
```

## Quick Start

**Prerequisites:** [Bun](https://bun.sh) (v1.3+), an LLM provider (local or cloud)

```bash
# Clone and install
git clone https://github.com/maziarzamani/spaceduck.git
cd spaceduck
bun install

# For the browser tool (one-time)
bunx playwright install chromium

# For sqlite-vec on macOS â€” install SQLite with extension support (one-time)
brew install sqlite

# Configure
cp .env.example .env
# Edit .env â€” set your provider and API keys (see .env.example for all options)

# Run
bun run dev
# Open http://localhost:3000
```

### Optional: Document Scanning (Marker)

To enable PDF-to-markdown conversion via the `marker_scan` tool, install [Marker](https://github.com/VikParuchuri/marker) separately:

```bash
pip install marker-pdf   # requires Python 3.10+, PyTorch
```

When `marker_single` is on your PATH, the tool is automatically registered at startup. Upload a PDF through the web UI (paperclip button or drag-and-drop) and the assistant will process it automatically.

> **License note:** Marker is GPL-3.0 with Open Rail model weight restrictions. Spaceduck never bundles Marker â€” it calls `marker_single` as an external process.

### Embedding Setup

Vector memory requires an embedding model. The default `.env.example` is configured for Amazon Bedrock (Titan V2):

```env
EMBEDDING_PROVIDER=bedrock                         # or gemini, lmstudio
EMBEDDING_MODEL=amazon.titan-embed-text-v2:0       # Titan V2: 100+ languages
EMBEDDING_DIMENSIONS=1024                          # Titan V2 supports 256 | 512 | 1024
```

To disable vector search entirely and use FTS5 keyword search only: `EMBEDDING_ENABLED=false`

See `.env.example` for all available configuration options.

## Development

```bash
# Run all tests
bun test --recursive

# Run specific test suites
bun test packages/core/              # Unit tests (agent, context, events, facts)
bun test packages/memory/            # Memory + vector embedding tests
bun test packages/tools/browser/     # Browser tool tests
bun test packages/tools/web-fetch/   # Web-fetch tests
bun test packages/tools/web-search/  # Web search + answer tests
bun test packages/tools/marker/      # Marker document scanner tests
bun test packages/gateway/src/__tests__/attachment-store.test.ts  # Attachment store tests

# Live E2E tests against Bedrock (requires AWS_BEARER_TOKEN_BEDROCK)
RUN_LIVE_TESTS=1 bun test packages/gateway/src/__tests__/e2e-bedrock.test.ts

# Dev server with hot reload
bun run dev

# Benchmarks (memory operations)
bun run bench
```

## Design Principles

- **No magic.** Every layer is explicit, handwritten TypeScript. No ORMs, no framework abstractions, no hidden behavior.
- **Result, not throw.** Library code returns `Result<T, E>` â€” errors are values, not exceptions.
- **Stream everything.** LLM responses stream token-by-token over WebSocket to the UI.
- **Memory is semantic.** Facts are embedded as vectors for meaning-based recall, with FTS5 keyword fallback.
- **Extraction is eager.** Facts are persisted after every turn via `afterTurn()` â€” cross-conversation recall works even in short conversations.
- **Tools return text.** Tool results are plain strings the LLM can read â€” including errors. No structured schemas, no silent failures.
- **Provider-agnostic.** Swap chat models, embedding models, or providers via a single env var. Bring your own by implementing the `Provider` or `EmbeddingProvider` interface.

## Roadmap

All planned features are tracked inline in the [Status](#status) tables above (marked ðŸ”œ). The highest-priority items right now:

1. **Configuration system** â€” replace flat `.env` with a structured config file. The current approach does not scale: no nesting, no type safety, no multi-environment support.
2. **Per-user isolation** â€” scope facts by user identity so multi-user setups don't leak memory across people.
3. **Provider fallback chain** â€” auto-retry with a secondary provider on failure or timeout.
4. **Memory inspector** â€” Web UI panel to browse, edit, and delete stored facts.

---

<p align="center">
  <sub>
    Built with patience and curiosity. Spaceduck is a personal project â€” not a product, not a startup.
    Just a duck in a spacesuit, trying to be helpful.
  </sub>
</p>

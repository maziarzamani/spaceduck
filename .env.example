# spaceduck environment configuration
# Copy this to .env and fill in the values you need.
# Lines starting with # are comments. Uncomment a line to activate it.

# ── Server ────────────────────────────────────────────────────────────────────
PORT=3000                                # HTTP + WebSocket listen port
LOG_LEVEL=info                           # debug | info | warn | error

# ── Auth & Pairing ────────────────────────────────────────────────────────────
SPACEDUCK_REQUIRE_AUTH=1                 # require token auth (0 to disable — prints warning)
SPACEDUCK_PAIRING_LOG_CODE=0             # log pairing codes to console (default: off, use /pair page)
# SPACEDUCK_MDNS=0                       # mDNS advertising (future)

# ── Chat Provider ─────────────────────────────────────────────────────────────
# Choose one provider and configure its section below.
PROVIDER_NAME=gemini                     # gemini | bedrock | openrouter | lmstudio
PROVIDER_MODEL=gemini-2.5-flash         # model name (provider-specific, see defaults below)

# Optional persona injected as the system prompt for every conversation.
# SYSTEM_PROMPT=You are spaceduck, a helpful and concise AI assistant.

# ── Google Gemini ─────────────────────────────────────────────────────────────
# Required when PROVIDER_NAME=gemini or EMBEDDING_PROVIDER=gemini
# Get your key at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=
# Default PROVIDER_MODEL: gemini-2.5-flash

# ── Amazon Bedrock ────────────────────────────────────────────────────────────
# Required when PROVIDER_NAME=bedrock or EMBEDDING_PROVIDER=bedrock
# Auth: Bedrock API key (Bearer token)
# Generate at: AWS Console → Amazon Bedrock → API keys
# Docs: https://docs.aws.amazon.com/bedrock/latest/userguide/api-keys.html
#
# AWS_BEARER_TOKEN_BEDROCK=bedrock-api-key-...   # paste your Bedrock API key here
# AWS_REGION=us-east-1                           # region where the model is enabled (required)
# PROVIDER_MODEL=us.anthropic.claude-sonnet-4-20250514:0
#   Other models: us.amazon.nova-2-lite-v1:0, us.anthropic.claude-3-5-haiku-20241022-v1:0

# ── OpenRouter ────────────────────────────────────────────────────────────────
# Required when PROVIDER_NAME=openrouter (also used for web_answer if no PERPLEXITY_API_KEY)
# Get your key at: https://openrouter.ai/keys
# OPENROUTER_API_KEY=sk-or-...
# Default PROVIDER_MODEL: nvidia/nemotron-3-nano-30b-a3b:free

# ── LM Studio ────────────────────────────────────────────────────────────────
# Required when PROVIDER_NAME=lmstudio (runs locally, no API key needed by default)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1   # OpenAI-compatible endpoint
# LMSTUDIO_API_KEY=                             # optional, only if your server requires auth
# Default PROVIDER_MODEL: qwen/qwen3-4b-thinking-2507

# ── Memory ────────────────────────────────────────────────────────────────────
MEMORY_BACKEND=sqlite                    # only sqlite is supported currently
MEMORY_CONNECTION_STRING=spaceduck.db    # file path for SQLite, or :memory: for ephemeral

# ── Embedding / Vector Memory ────────────────────────────────────────────────
# Enables semantic (cross-lingual) recall across conversations.
# Set EMBEDDING_ENABLED=false to fall back to keyword search only (FTS5).
#
# EMBEDDING_ENABLED=true                          # default: true (vectors enabled)
# EMBEDDING_PROVIDER=bedrock                      # bedrock | gemini | lmstudio (defaults to PROVIDER_NAME)
# EMBEDDING_MODEL=amazon.titan-embed-text-v2:0    # model name (provider-specific)
# EMBEDDING_DIMENSIONS=1024                        # vector dimensions (must match model)
#
# Bedrock — Titan Text Embeddings V2:
#   Supports dimensions: 256 | 512 | 1024
#   EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
#   Uses the same Bedrock API key (AWS_BEARER_TOKEN_BEDROCK) as the chat provider above
#
# Gemini — text-embedding-004:
#   EMBEDDING_PROVIDER=gemini
#   EMBEDDING_MODEL=text-embedding-004
#   EMBEDDING_DIMENSIONS=768
#
# LM Studio — any local embedding model:
#   EMBEDDING_PROVIDER=lmstudio
#   EMBEDDING_MODEL=text-embedding-qwen3-embedding-8b
#   EMBEDDING_DIMENSIONS=4096
#   EMBEDDING_INSTRUCTION=                        # optional query prefix for asymmetric models

# ── Web Search ────────────────────────────────────────────────────────────────
# Structured search (web_search tool) — enable by setting at least one API key:
# SEARCH_PROVIDER=brave                  # brave | searxng (default: brave)
# BRAVE_API_KEY=BSA...                   # https://api-dashboard.search.brave.com
# SEARXNG_URL=http://localhost:8080      # self-hosted SearXNG instance URL
# SEARXNG_USER_AGENT=                    # optional custom user-agent for SearXNG
#
# Synthesized answers (web_answer tool) — enable by setting one:
# PERPLEXITY_API_KEY=pplx-...            # direct API (recommended, best citation support)
# — or use OPENROUTER_API_KEY above      # routes through OpenRouter (citations best-effort)

# ── WhatsApp Channel ─────────────────────────────────────────────────────────
# Enable the WhatsApp channel (uses Baileys / WhatsApp Web protocol).
# On first start, scan the QR code printed in the terminal with your phone.
# WHATSAPP_ENABLED=false                          # set to true to activate
# WHATSAPP_AUTH_DIR=data/whatsapp-auth            # session credentials directory (gitignored)

# ── Document Scanning (optional) ─────────────────────────────────────────────
# PDF-to-markdown conversion via Marker. The marker_scan tool is auto-registered
# at startup when marker_single is found on PATH. Spaceduck never bundles Marker.
#
# Install:  pip install marker-pdf  (requires Python 3.10+, PyTorch)
# License:  GPL-3.0 code, Open Rail model weights
# Details:  https://github.com/VikParuchuri/marker
#
# MARKER_USE_LLM=false                   # opt-in: use LLM inside Marker for higher
#                                        # accuracy (adds cost + privacy implications)
# UPLOAD_MAX_SIZE_MB=50                  # max file upload size in MB (default: 50)

# ── Testing ───────────────────────────────────────────────────────────────────
# These are only used when running the test suite, not in production.
# RUN_LIVE_TESTS=1                       # enable E2E tests that call live APIs

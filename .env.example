# spaceduck environment configuration
# Copy this to .env and fill in the values you need.
# Lines starting with # are comments. Uncomment a line to activate it.
#
# NOTE: AI provider, model, API keys, system prompt, and tool secrets are now
# managed in spaceduck.config.json5 (via the Settings UI or config API).
# This file is for deployment knobs only.

# ── Server ────────────────────────────────────────────────────────────────────
PORT=3000                                # HTTP + WebSocket listen port
LOG_LEVEL=info                           # debug | info | warn | error

# ── Auth & Pairing ────────────────────────────────────────────────────────────
SPACEDUCK_REQUIRE_AUTH=1                 # require token auth (0 to disable — prints warning)
SPACEDUCK_PAIRING_LOG_CODE=0             # log pairing codes to console (default: off, use /pair page)
# SPACEDUCK_MDNS=0                       # mDNS advertising (future)

# ── Memory ────────────────────────────────────────────────────────────────────
MEMORY_BACKEND=sqlite                    # only sqlite is supported currently
MEMORY_CONNECTION_STRING=data/spaceduck.db    # file path for SQLite, or :memory: for ephemeral

# ── Embedding / Vector Memory ────────────────────────────────────────────────
# Enables semantic (cross-lingual) recall across conversations.
# Set EMBEDDING_ENABLED=false to fall back to keyword search only (FTS5).
#
# EMBEDDING_ENABLED=true                          # default: true (vectors enabled)
# EMBEDDING_PROVIDER=bedrock                      # bedrock | gemini | lmstudio (defaults to AI provider)
# EMBEDDING_MODEL=amazon.nova-2-multimodal-embeddings-v1:0   # Nova 2: 200 languages, purpose-optimized
# EMBEDDING_DIMENSIONS=1024                        # vector dimensions (must match model)
#
# Bedrock — Nova 2 Multimodal Embeddings (recommended):
#   Supports dimensions: 256 | 384 | 1024 | 3072
#   EMBEDDING_MODEL=amazon.nova-2-multimodal-embeddings-v1:0
#   Uses the same Bedrock API key as the chat provider (set in Settings)
#
# Bedrock — Titan Text Embeddings V2 (legacy):
#   Supports dimensions: 256 | 512 | 1024
#   EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
#
# Gemini — text-embedding-004:
#   EMBEDDING_PROVIDER=gemini
#   EMBEDDING_MODEL=text-embedding-004
#   EMBEDDING_DIMENSIONS=768
#
# LM Studio — any local embedding model:
#   EMBEDDING_PROVIDER=lmstudio
#   EMBEDDING_MODEL=text-embedding-qwen3-embedding-8b
#   EMBEDDING_DIMENSIONS=4096
#   EMBEDDING_INSTRUCTION=                        # optional query prefix for asymmetric models

# ── LM Studio Base URL ───────────────────────────────────────────────────────
# Only needed when using LM Studio as your AI or embedding provider.
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ── WhatsApp Channel ─────────────────────────────────────────────────────────
# Enable/disable is configured in Settings (channels.whatsapp.enabled).
# This is just the auth directory for session persistence.
# WHATSAPP_AUTH_DIR=data/whatsapp-auth            # session credentials directory (gitignored)

# ── Document Scanning (optional) ─────────────────────────────────────────────
# PDF-to-markdown conversion via Marker. The marker_scan tool is auto-registered
# at startup when marker_single is found on PATH. Spaceduck never bundles Marker.
#
# Install:  pip install marker-pdf  (requires Python 3.10+, PyTorch)
# License:  GPL-3.0 code, Open Rail model weights
# Details:  https://github.com/VikParuchuri/marker
#
# MARKER_USE_LLM=false                   # opt-in: use LLM inside Marker for higher
#                                        # accuracy (adds cost + privacy implications)
# UPLOAD_MAX_SIZE_MB=50                  # max file upload size in MB (default: 50)

# ── Speech-to-Text (optional) ────────────────────────────────────────────────
# Voice dictation via local Whisper. The mic button appears in the UI when
# `whisper` is found on PATH at gateway startup. Spaceduck never bundles Whisper.
#
# Install:  pip install openai-whisper  (requires Python 3.9+, ffmpeg)
# Details:  https://github.com/openai/whisper
#
# Whisper models:
#   Size    Params   English-only   Multilingual   VRAM     Speed
#   tiny    39 M     tiny.en        tiny           ~1 GB    ~10x
#   base    74 M     base.en        base           ~1 GB    ~7x
#   small   244 M    small.en       small          ~2 GB    ~4x
#   medium  769 M    medium.en      medium         ~5 GB    ~2x
#   large   1550 M   N/A            large          ~10 GB   1x
#   turbo   809 M    N/A            turbo          ~6 GB    ~8x
#
# Use the .en variants (e.g. small.en) for English-only — they're faster and
# more accurate for English. Multilingual variants support all languages.
#
# SPACEDUCK_STT_MODEL=small             # whisper model (see table above)
# SPACEDUCK_STT_LANGUAGE=               # ISO 639-1 code (da, en, de, etc.) — empty = auto-detect
#                                        # Full list: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py
# SPACEDUCK_WHISPER_PATH=               # explicit path to whisper binary (default: search PATH)
# SPACEDUCK_STT_MAX_SECONDS=120         # UI auto-stop recording limit (server enforces max bytes only)
# SPACEDUCK_STT_MAX_BYTES=15728640      # max audio upload size in bytes (default: 15 MB)
# SPACEDUCK_STT_TIMEOUT_MS=300000       # whisper subprocess kill deadline in ms (default: 5 min)

# ── Config Directory ──────────────────────────────────────────────────────────
# SPACEDUCK_CONFIG_DIR=data/config       # directory for spaceduck.config.json5

# ── Testing ───────────────────────────────────────────────────────────────────
# These are only used when running the test suite, not in production.
# RUN_LIVE_TESTS=1                       # enable E2E tests that call live APIs
